{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9caf9f45ff0ece",
   "metadata": {},
   "source": [
    "# 1、获取大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce788165255a6aee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:49:13.042306Z",
     "start_time": "2025-08-21T13:49:05.622065Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Softwares\\MiniConda\\envs\\langchain-tutorial\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='“大模型”是指在人工智能领域中，特别是自然语言处理（NLP）和机器学习中，参数量非常庞大的神经网络模型。这类模型通常包含数亿甚至数百亿个参数，具有强大的学习和推理能力，可以理解和生成自然语言、图像、音频、视频等多种类型的数据。\\n\\n### 一、大模型（Large Model）的定义\\n大模型一般指的是在训练过程中使用海量数据，并通过大规模计算资源进行训练的深度学习模型。它们通常基于深度神经网络（如Transformer），并具有以下几个核心特征：\\n\\n1. **参数量大**：通常是数十亿到数千亿参数，远超传统小模型。\\n2. **训练数据多**：使用大量的文本、图像、语音等数据进行训练。\\n3. **计算资源需求高**：需要高性能的GPU/TPU集群，以及大量的计算时间。\\n4. **能力强大**：能完成多种复杂的任务，如自然语言理解、文本生成、语音识别、图像识别等。\\n5. **泛化能力好**：在未见过的数据上也能表现出较佳的性能，具有较好的迁移能力。\\n\\n---\\n\\n### 二、大模型的应用场景\\n大模型因其强大的泛化能力和多模态处理能力，被广泛应用于多个领域，包括但不限于：\\n\\n- **自然语言处理（NLP）**：\\n  - 文本生成（如文章、故事、对话）\\n  - 问答系统（如Chatbot）\\n  - 机器翻译\\n  - 情感分析\\n  - 文本摘要\\n  - 拼写和语法纠错\\n\\n- **计算机视觉（CV）**：\\n  - 图像分类\\n  - 目标检测\\n  - 图像生成\\n  - 图像修复\\n\\n- **语音识别与生成**：\\n  - 语音转文字\\n  - 文字转语音\\n  - 语音合成\\n\\n- **多模态任务**：\\n  - 文字、图像、语音联合处理（如图文生成、视频分析）\\n\\n---\\n\\n### 三、大模型的代表\\n目前比较知名的大模型有：\\n\\n- **自然语言处理**：\\n  - GPT 系列（GPT-1, GPT-2, GPT-3, GPT-4）\\n  - BERT、RoBERTa、T5\\n  - Megatron、PaLM、Llama、Qwen（通义千问）、通义万相等\\n\\n- **图像处理**：\\n  - DALL-E\\n  - Stable Diffusion\\n  - Midjourney\\n\\n- **视频处理**：\\n  - CogView、Runway ML、DeepMind 的视频生成模型\\n\\n- **多模态模型**：\\n  - CLIP、ALIGN、FLUX、有界模型（如百度文心一言、腾讯混元、阿里通义千问等）\\n\\n---\\n\\n### 四、大模型的优势\\n1. **强大的文本理解和生成能力**：\\n   - 能理解上下文，生成连贯、自然的回复。\\n   - 能完成复杂的任务，如写小说、写代码、创作诗歌等。\\n\\n2. **多任务学习**：\\n   - 一个大模型可以同时处理许多不同的任务（如问答、翻译、摘要、写作、编码等）。\\n\\n3. **少样本学习能力**：\\n   - 在少量提示（Prompt）的情况下也能表现出不错的推理能力。\\n\\n4. **迁移能力强**：\\n   - 可以在不同任务之间迁移知识，降低对特定任务的重新训练需求。\\n\\n5. **持续学习与更新能力**：\\n   - 通过微调（Fine-tuning）可以快速适应新任务或新数据。\\n\\n---\\n\\n### 五、大模型的挑战\\n1. **资源消耗大**：\\n   - 需要大量的计算资源和存储空间，训练和部署成本高。\\n\\n2. **能耗高**：\\n   - 大模型的训练成本极高，对电力和算力消耗很大。\\n\\n3. **伦理与安全问题**：\\n   - 模型可能会生成不实或有害内容。\\n   - 存在数据隐私和算法偏见等问题。\\n\\n4. **黑箱问题**：\\n   - 大模型的内部逻辑难以解释，这在某些应用场景中可能带来问题。\\n\\n5. **部署与应用门槛高**：\\n   - 对于非专业用户来说，使用大模型的门槛较高，需要一定的技术背景。\\n\\n---\\n\\n### 六、大模型的发展趋势\\n1. **预训练+微调（PTuning）**：\\n   - 模型在大规模数据上进行预训练，然后通过微调适应具体任务或场景。\\n\\n2. **模型压缩**：\\n   - 为降低使用成本，研究者们在探索模型压缩技术（如知识蒸馏、量化、剪枝等）。\\n\\n3. **垂直行业定制**：\\n   - 针对特定行业（如医疗、法律、金融、教育）进行定制化的大模型开发。\\n\\n4. **多模态融合**：\\n   - 趋向于同时处理文本、图像、语音等多类型数据，提升跨模态理解和生成能力。\\n\\n5. **开源共享**：\\n   - 越来越多的大模型开源（如Llama系列、Qwen等），推动AI技术的普及和发展。\\n\\n---\\n\\n### 七、大模型 vs 小模型\\n| 特性 | 大模型 | 小模型 |\\n|------|--------|--------|\\n| 参数量 | 数十亿至千亿 | 几万至百万 |\\n| 训练数据 | 巨量数据 | 较少数据 |\\n| 计算资源 | 高 | 低 |\\n| 任务处理能力 | 多样、泛化强 | 任务单一或特定 |\\n| 部署成本 | 高 | 低 |\\n| 推理速度 | 较慢 | 快 |\\n| 适用场景 | 复杂任务、大生产、多模态 | 轻量级应用、边缘设备、定制任务 |\\n\\n---\\n\\n### 八、大模型的未来\\n随着AI技术的发展，大模型正逐步从实验室走向实际应用，并在**语言理解、内容创作、智能助手、智能客服、数据分析、教育、医疗、游戏**等多个领域产生深远影响。未来的发展方向将进一步聚焦于：\\n- 更高效的模型结构\\n- 更高的推理速度\\n- 更好的解释性和可控性\\n- 更广泛的应用场景\\n\\n---\\n\\n### 总结\\n大模型是人工智能领域中一个重要的发展方向，它代表了深度学习技术在参数规模、数据规模和任务复杂性上的突破。虽然存在资源消耗大、伦理问题等挑战，但它们在语言理解、生成、多任务处理等方面的能力远超以往的模型。随着技术的进步，大模型将会越来越普及，成为人工智能应用的重要基石。\\n\\n如果你有具体的大模型类型（如Llama、GPT、Qwen）或是想了解某个应用领域，我可以进一步详细说明。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1456, 'prompt_tokens': 16, 'total_tokens': 1472, 'completion_tokens_details': {'accepted_prediction_tokens': None, 'audio_tokens': None, 'reasoning_tokens': 0, 'rejected_prediction_tokens': None}, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'Qwen/Qwen3-8B', 'system_fingerprint': '', 'id': '019bceeb33e680e0b881c604f2212bd7', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--019bceeb-273c-7a30-aec1-24eacb8f8fca-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 16, 'output_tokens': 1456, 'total_tokens': 1472, 'input_token_details': {}, 'output_token_details': {'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "#导入 dotenv 库的 load_dotenv 函数，用于加载环境变量文件（.env）中的配置\n",
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()  #加载当前目录下的 .env 文件\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"SILICON_API_KEY\")\n",
    "os.environ['OPENAI_BASE_URL'] = os.getenv(\"SILICON_URL\")\n",
    "\n",
    "# 创建大模型实例\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen3-8B\")  # 默认使用 gpt-3.5-turbo\n",
    "\n",
    "# 直接提供问题，并调用llm\n",
    "response = llm.invoke(\"什么是大模型？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd908d3010884a30",
   "metadata": {},
   "source": [
    "# 2、使用提示词模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540706aaa244853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:50:29.883037Z",
     "start_time": "2025-08-21T13:50:21.403902Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# 需要注意的一点是，这里需要指明具体的role，在这里是system和用户\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是世界级的技术文档编写者\"),\n",
    "    (\"user\", \"{input}\")  # {input}为变量\n",
    "])\n",
    "\n",
    "# 我们可以把prompt和具体llm的调用和在一起。\n",
    "chain = prompt | llm\n",
    "message = chain.invoke({\"input\": \"大模型中的LangChain是什么?\"})\n",
    "print(message)\n",
    "\n",
    "# print(type(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7636c01962fa0c2e",
   "metadata": {},
   "source": [
    "# 3、 使用输出解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23406024ea864619",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:51:18.550994Z",
     "start_time": "2025-08-21T13:51:16.084164Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser,JsonOutputParser\n",
    "\n",
    "# 初始化模型\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 创建提示模板\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是世界级的技术文档编写者。\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 使用输出解析器\n",
    "# output_parser = StrOutputParser()\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "# 将其添加到上一个链中\n",
    "# chain = prompt | llm\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "# 调用它并提出同样的问题。答案是一个字符串，而不是ChatMessage\n",
    "# chain.invoke({\"input\": \"LangChain是什么?\"})\n",
    "chain.invoke({\"input\": \"LangChain是什么? 用JSON格式回复，问题用question，回答用answer\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152461370a49413f",
   "metadata": {},
   "source": [
    "# 4、使用向量存储"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182765067f9f4eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:53:08.453078Z",
     "start_time": "2025-08-21T13:52:40.823449Z"
    }
   },
   "outputs": [],
   "source": [
    "# 导入和使用 WebBaseLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "        web_path=\"https://www.gov.cn/yaowen/liebiao/202601/content_7054758.htm\",\n",
    "        bs_kwargs=dict(parse_only=bs4.SoupStrainer(id=\"UCAP-CONTENT\"))\n",
    "    )\n",
    "docs = loader.load()\n",
    "# print(docs)\n",
    "\n",
    "# 对于嵌入模型，这里通过 API调用\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 使用分割器分割文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "print(len(documents))\n",
    "# 向量存储  embeddings 会将 documents 中的每个文本片段转换为向量，并将这些向量存储在 FAISS 向量数据库中\n",
    "vector = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b38c85dfb39fe",
   "metadata": {},
   "source": [
    "# 5、RAG(检索增强生成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa2c4bd0704d50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:54:32.319977Z",
     "start_time": "2025-08-21T13:54:25.549076Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retriever.search_kwargs = {\"k\": 3}\n",
    "docs = retriever.invoke(\"建设用地使用权是什么？\")\n",
    "\n",
    "# for i,doc in enumerate(docs):\n",
    "#     print(f\"⭐第{i+1}条规定：\")\n",
    "#     print(doc)\n",
    "\n",
    "# 6.定义提示词模版\n",
    "prompt_template = \"\"\"\n",
    "你是一个问答机器人。\n",
    "你的任务是根据下述给定的已知信息回答用户问题。\n",
    "确保你的回复完全依据下述已知信息。不要编造答案。\n",
    "如果下述已知信息不足以回答用户的问题，请直接回复\"我无法回答您的问题\"。\n",
    "\n",
    "已知信息:\n",
    "{info}\n",
    "\n",
    "用户问：\n",
    "{question}\n",
    "\n",
    "请用中文回答用户问题。\n",
    "\"\"\"\n",
    "# 7.得到提示词模版对象\n",
    "template = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# 8.得到提示词对象\n",
    "prompt = template.format(info=docs, question='本次会议都有谁出席')\n",
    "\n",
    "## 9. 调用LLM\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9feeb62844c3439",
   "metadata": {},
   "source": [
    "# 6、使用Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb95f11df6bc53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T13:56:14.407134Z",
     "start_time": "2025-08-21T13:56:03.168429Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# 检索器工具\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"CivilCodeRetriever\",\n",
    "    \"搜索有关中华人民共和国民法典的信息。关于中华人民共和国民法典的任何问题，您必须使用此工具!\",\n",
    ")\n",
    "\n",
    "tools = [retriever_tool]\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# https://smith.langchain.com/hub\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# 运行代理\n",
    "agent_executor.invoke({\"input\": \"建设用地使用权是什么\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
